---
title: "Applied R in the Classroom"
author: "JD Long & Dusty Turner"
bibliography: bibliography.bib
output:
 bookdown::word_document2:
  reference_docx: template.docx
  fig_caption: yes
link-citations: yes
csl: austral-ecology.csl
# csl: chicago-library-list.csl
biblio-style: authoryear
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen=1, digits=2)
```

## Abstract

R with support from a number of add in packages forms an excellent teaching tool which can greatly enhance learning of exploratory data analysis (EDA) and linear regression. R aided by a few packages, boosts students up the learning curve and allows them to rapidly accelerate their analytic skillset. This paper illustrates using R along with the packages `tidyverse`, `GGally`, `esquisse`, and `lindia` to walk through an example of basic EDA and linear regression that might be used in an introductory class along with code examples for every step. Teaching with R can give learners control of their analysis, lower the intimidating coding barrier, and provide a platform on which to learn modeling and analysis. When teachers use R, students will walk away with a set of skills they can take with them into industry or future academic pursuits. 


## Introduction

The Father of Modern Economics, Adam Smith, once frustratingly stated [@smith]:

> The discipline of colleges and universities is in general contrived, not for the benefit of the students, but for the... ease of the masters. 

<!-- > The discipline of colleges and universities is in general contrived, not for the benefit of the students, but for the interest, or more properly speaking, for the ease of the masters. -->

<!-- https://www.adamsmith.org/adam-smith-quotes -->
<!-- This article is in the lit review folder -->

Adam Smith is making the claim that methods of instruction used by professors are those which are easiest for the instructor, but not necessarily what is best for the student. This is understandable, as research and other administrative demands force instructors to rely on tried and tested teaching techniques which are familiar to the teacher and possibly not what will best equip the student to be most successful in their career.
The authors of this article will make the case that the R open source statistical programming language can bridge this gap between  Smith’s proverbial teacher’s ease and a student’s benefit. As R continues to be one of the more popular coding languages for statistical analysis with ever increasing technical support, the barrier for entry keeps falling. There are many tools available as add-ons to R which can aide the teaching process to get students loading and exploring data quickly with manageable overhead for the instructor. With ample open source support, a wide acceptance in industry, and many additional features to explore and present data, teaching with R both satisfies the ease for the instructor and has long term benefits for the students. Learning the basics of R means students have a tool set that they can take with them to either future academic career paths or to apply in industry.

The growth of the R language can be appreciated if we look at the increase in R questions being asked each month on the popular question and answer site, Stack Overflow: [@stack] In figure \@ref(fig:stackoverflow) below we can see that R related new question activity on the site has grown steadily from the site's origin in 2008. Currently there are over 4000 new R related questions every month. 

```{r stackoverflow, fig.cap='R Growth on Stack Overflow', echo=FALSE, out.width = "300px", message=FALSE, warning=FALSE, fig.align='left', dpi=300}
# #source description: https://data.stackexchange.com/meta.stackoverflow/revision/338993/614151/r-trends-questions-per-tag-per-month
# url <- "https://data.stackexchange.com/stackoverflow/csv/614151"
# dat <- read_csv(url)
# write_csv(dat, "01_data/stackoverflow.csv")
library(tidyverse)

read_csv("01_data/stackoverflow.csv") %>%
  mutate(Month = as.Date(Month)) %>%
  filter(TagName == 'r') ->
  so_r_data

ggplot(so_r_data) +
  aes(x = Month, y = Questions) +
  geom_line(size = 1.25, colour = "#0c4c8a") +
  labs(x = "Month", y = "Questions", title = "R Questions on Stack Overflow") +
  theme_bw()

```

Equipping students with a popular tool that also enables them to work quickly while learning is something we are certain Adam Smith would appreciate.

## The R Ecosystem

The advantages to using R in an academic setting or in industry are myriad. Since R and all the tooling we discuss below are open source, they have no financial costs to adoption. In addition, R has a very rich ecosystem of add-on packages that expand R and add functionality. These packages add features ranging from adding the ability to connect to commercial database systems to implementation of new machine learning algorithms. The nature of open source allows user written packages and routines to be easily distributed as well. In addition, the popularity of R in academia leads to availability of packages containing state-of-the-art methods.

### CRAN 

The online home of R is the Comprehensive R Archive Network (CRAN). CRAN is where a new user can download R and access packages that expand R's functionality. There are currently more than 10,000 R packages hosted on CRAN for free download [@cran]. Some new users to R are overwhelmed by the sheer volume of packages. To help make sense of the CRAN ecosystem, CRAN has published CRAN Task Views which organize popular packages into categories of use (e.g. econometrics or spatial statistics). Each task view is written and maintained by a subject matter expert. There are more than 35 such task views which can help new R users make sense of the packages available in their areas of interest and know which packages are recommended by an expert in their domain of interest. This can provide instructors and students a curated view into packages that might match their interests or field of study: https://cran.r-project.org/web/views/

### RStudio

When R is downloaded from CRAN, it comes with an engine for executing R code along with a few core packages for doing statistical analysis and graphics. Collectively these tools are referred to as "Base R". Base R comes with a basic text editor for editing and executing R scripts.  However, most users quickly discover that writing R code is easier with an integrated development environment (IDE). The most popular IDE for R is RStudio Desktop which we highly recommend for teaching.

RStudio.com provides RStudio Desktop for free as open source software. In addition to the desktop IDE, RStudio makes a server based IDE for using R on remote machines. RStudio Server is also available in a professional version that offers more features such as authentication and collaborative editing. RStudio offers its professional tools to academics for free. Go to https://www.rstudio.com/pricing/academic-pricing/ for more info. 

For many instructors, the freely available RStudio.cloud service (http://rstudio.cloud) greatly simplifies instruction by providing a fully functional and configured R and RStudio environment running on cloud hosted hardware. For screenshots in this article we will exclusively use RStudio.cloud in our examples. Instructors can set up projects in RStudio.cloud and share those projects with students to simplify distributing course material. The basic RStudio.cloud interface is shown in figure \@ref(fig:icons) below. 

```{r icons, fig.cap='RStudio.cloud', echo=FALSE, eval=TRUE, fig.width=4, fig.height=3}
knitr::include_graphics("03_figures/rstudio.cloud.png")
```

Instructors who do not want to use the cloud solutions, or can not access them because of connectivity restrictions, can download and install R and RStudio on local hardware. For details on downloading and installing, see section 1.1 in R Cookbook [@teetor_long], available online at https://rc2e.com/gettingstarted#recipe-id001.

### Projects

RStudio introduces a powerful organizational tool called an RStudio Project. Projects help users by doing the following:

- Storing RStudio project settings
- Restoring window position in RStudio so when a project is closed and repoened, window contents are preserved.
- Setting the working directory 

RStudio creates a project file with an *.Rproj* extension in the project directory. RStudio also creates a hidden directory, *.Rproj.user*, for temporary files related to your project.

We have found that helping students organize their files using projects from the start helps students build good organizational practices and prevents lost files and file path related issues that commonly flummox new learners. Although, instructors should expect to teach the basics of absolute and relative file paths ^[absolute file paths are the entire file path starting from the root directory while relative files paths are relative from a starting directory.], as this concept is sometimes new to learners and can slow the learning progress. 

### Tidyverse

In addition to the RStudio IDE, the RStudio company supports the development of a number of open source packages designed to work together to make R easier to use and faster to learn. These libraries are collectively known as the "Tidyverse". The most concise definition of the Tidyverse comes directly from its originator and core maintainer, Wickham [@rstudioblog]:

> The tidyverse is a set of packages that work in harmony because they share 
> common data representations and API design. The tidyverse package is designed 
> to make it easy to install and load core packages from the tidyverse in a 
> single command. The best place to learn about all the packages in the 
> tidyverse and how they fit together is *[R for Data Science](http://r4ds.had.co.nz)*.


The authors have had very good experiences with introducing learners to the Tidyverse from the very beginning of the learning journey because these tools help learners achieve very quick successes which, in turn, keeps them engaged in the learning process. The popular plotting package `ggplot2` and the data manipulation package `dplyr` are both core Tidyverse packages.

The Tidyverse meta-package, like any CRAN package, can be installed from the R Console:

```{r tidy, eval=FALSE, include=TRUE}
install.packages("tidyverse")
```

#### Tidyverse Packages
When a user installs the Tidyverse, 19 packages are installed  [@dustysreference;@jdsreference]. When the user loads the tidyverse using `library(tidyverse)` a core subset of 8 packages are loaded into R. To use any of the packages not loaded with the core Tidyverse, a user must explicitly load those packages (e.g. `library(readxl)`) or call the packages using the package name prefix (e.g. `readxl::read_xlsx()` to run the `read_xlsx()` function from the `readxl` package).

The packages listed below are in the "Core Tidyverse" and loaded with `library(tidyverse)`. 

***Core Tidyverse***

`ggplot2`: data visualization  
`dplyr`: data manipulation   
`tidyr`: data reshaping  
`readr`: data import  
`purrr`: functional programming   
`tibble`: tidy dataframes   
`stringr`: string manipulation   
`forcats`: factor use   

***Additional Tidyverse***

There are 11 additional Tidyverse packages that install, but do not automatically load. These add functions for more specialized uses [@dustysreference;@jdsreference].

*Import*

`readxl`: reading Excel files  
`haven`: reading SPSS, Stata, and SAS data  
`jsonlite`: manipulating JSON   
`xml2`: reading xml   
`httr`: accessing web APIs  
`rvest`: web scraping  
`feather`: data sharing with Python and beyond  

*Wrangle*

`lubridate`: date manipulation   
`hms`: time-of-day manipulation

*Modeling* 

`modelr`: modeling pipelines  
`broom`: takes model results and makes them tidy

More info on each can be found at https://tidyverse.tidyverse.org.

## Harnessing the Power of R, Tidyverse, and other Helpful Packages 

In the following sections, we will highlight some of the features of R and the `tidyverse` and how they can be useful in a classroom setting while teaching new students. The reader will notice the authors use many packages to support their analysis and recommend teachers do the same when instructing students. These prebuilt, add-on packages make syntax simple, easy to interpret, and less intimidating for new users. 

### Loading Data (Gapminder)

To aide our instructions, we will explore the Gapminder data set. The Gapminder data set is created by the Gapminder Foundation which is a non-profit organization that promotes sustainable global development [@gapminder].

Showing students how to load in example data is a crucial first step. Data can be easily loaded from the local file system:

```{r readdata, message=FALSE, warning=FALSE}
library(tidyverse)
gapminder <- read_csv("01_data/gapminder.csv")
```

Or directly from a URL:

```{r readdata2, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
gapminder <- read_csv("https://raw.githubusercontent.com/CerebralMastication/r_for_the_student/master/01_data/gapminder.csv")
```

> As a quick aside, a common stumbling block for students is executing lines of code. RStudio makes this simple. `Ctrl` + `Enter` (for Windows) or `Command`+`Enter` (for MAC) will execute the line of code where the cursor currently exists. Students can also execute multiple lines of code by highlighting the desired code and pressing `Ctrl` + `Enter` (Windows) or `Command`+`Enter`(MAC).

Once the student reads the data into R, the environment tab in the top right of the computer will reflect that the data is loaded. And example environment pane after loading the gapminder data is shown in figure \@ref(fig:icons2) below. 

```{r icons2, fig.cap='Environment With Gapminder Data', echo=FALSE, eval=TRUE, out.width = "300px"}
knitr::include_graphics("03_figures/environment.png")
```

### Initial Data Exploration

Simply printing the resulting data frame can tell students a bundle of information about the data just loaded. Let's look at the output below.

```{r showgapminder, eval=TRUE, message=FALSE, warning=FALSE,include=TRUE}
gapminder
```

From the output above, one can see the `gapminder` data set is a `tibble` consisting of 1,704 observational units with 6 columns of information. When reading in data, the `read_csv` command identifies the most likely class of data for each column. When we print the data out in R, the display lists the class below the column name. We can see that we have a mix of `character` and `double` class types. A `tibble` is a Tidyverse take on R's traditional `data.frame`. We have found that it usually is sufficient to tell students that "a `tibble` is a table." Since the goal is to get students using data to *do* things we often do not spend excessive time on definitions and instead focus on helping students doing something interesting. 

Students also notice that printing out the data does not provide everything an analyst would like to now about the data. One can see that the output provides information about countries, but are they all Afghanistan? Likely no, as you can see there are 1,694 more rows and they probably are not all Afghanistan. Let's look at other ways to understand the data. 

We recommend using the `skim` command from the `skimr` library [@skimr]. Students will need to download the `skimr` package from CRAN.

```{r installskimr, eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
install.packages("skimr")
```

```{r showskimr, echo=TRUE, eval=FALSE }
library(skimr)
skim(gapminder)
```

```{r skimrimage, fig.cap='Skim of Gapminder Data', echo=FALSE, eval=TRUE}
knitr::include_graphics("03_figures/skimr.png")
```

The `skim` output in \@ref(fig:skimrimage) gives students a much better overview of the data. `skim` separates the data by class and provides important information for each data type. We find that the `skim` function gives students the quickest and best description of the data. Other options of presenting detailed information about the data include the `summary(gapminder)` and `glimpse(gapminder)`. We typically only teach one of these techniques to quickly motivate the students by looking at the data instead of becoming distracted by worrying about the pros and cons of the different ways of exploring the data.

In the output above, for each class of data (`character`/`numeric`), `skim` provides how many missing, complete, and total (n) observations for each column.

For the character class, `skim` provides additional information about each column. This includes the min/max length of each character string as well as the number of unique (n_unique) observations. 

For the numeric class, `skim` provides mean, standard deviation (sd), and percentile breaks (p0, p25,...,p100). It also provides a small histogram to help visualize the distribution of your numeric data (hist).

This clearly does not give the student a full understanding of a data set, but it is a good start.  With just a `skim` the student still does not understand which countries are in the data and many other curiosities. We will provide more in-depth methods of understanding the data in the Plotting and Exploratory Data Analysis (EDA) section after we look briefly at the 6 `dplyr` verbs that allow students to begin rapidly exploring the data.  

### dplyr Verbs

Almost any time a student works with data, they will need to manipulate that data in some way. Below, we will introduce the main 6 `dplyr` verbs to help wrangle data to gain additional insight. These verbs, `select`, `filter`, `mutate`, `group_by`, `summarize`, `arrange` are explained in detail below. 

In order to motivate use of the aforementioned verbs, we will look to answer the following question: 

**What is the average GDP per country since 1980?**

#### Verb 1: select

To begin, we only need to work with certain columns. The relevant columns to this question are `country`, `year`, `pop`, and `gdpPercap`. We can make this selection using the `select` function. The first argument in the `select` function is the data we wish to select from. The subsequent arguments are the names of the columns from the data we will select. In the code below, we save our selected columns into a new `tibble` called `gapminder_selected`.

```{r selected}
gapminder_selected = select(gapminder, country, year, pop, gdpPercap)

gapminder_selected 
```

Once we view the data, we see that we still have 1704 rows but only 4 columns. 

#### Verb 2: filter

To further answer our question, we need to filter our data down to the years of interest. We can achieve this goal using the `filter` function. Like the `select` function, the first argument in the `filter` function is the data and subsequent argument is the logical statement of which you wish to filter. In the code below, we filter our selected data and save our filtered data into a new tibble called `gapminder_filtered`.

```{r filtered}
gapminder_filtered = filter(gapminder_selected, year >= 1980)

gapminder_filtered
```

Once we view the data, we see that our data now consist of 852 rows. This represents the rows of data since 1980.

#### Verb 3: mutate

The next step in answering our question is creating a column that contains the GDP. The `mutate` function creates new columns according to a specific function that we provide. To answer our question, we need to determine the GDP in each year. To find the GDP, we need to multiply the `gdpPercap` by the `pop`. Similar to the previous two verbs, the first argument in the `mutate` function is the data. Subsequent arguments are columns you wish to create with corresponding formulas. In the code below, we mutate our filtered data and save our mutated data into a new tibble called `gapminder_mutated`.

```{r mutated}
gapminder_mutated = mutate(gapminder_filtered, GDP = gdpPercap * pop)

gapminder_mutated
```

Once we view the data, we see the new column, `GDP`, has been added to the end of our tibble. 

#### Verb 4: group_by

The next step will be to group our data by the field of interest. In this instance, since we want to know GDP by country, we need to group the data by country. A way to conceptualize this step is to think of placing each group of data into a specific room. In subsequent steps we will apply a function to each group (or room) of data. Just like the previous verbs, the first argument in the `group_by` function is the data. The following arguments are the columns you wish to group by. In the code below, we group our mutated data and save our grouped data into a new tibble called `gapminder_grouped`.

```{r grouped}
gapminder_grouped = group_by(gapminder_mutated, country) 

gapminder_grouped
```

Students will notice that there appears to be no change to the data. This is mostly true as we have simply told R that we would like to apply future functions to each group of data instead of to the entire tibble. The only difference in output is a note explaining what the data has been grouped into and the number of groups. In this case, it explains the data is grouped by `country` and that there are 142 groups. 

#### Verb 5: summarise

Next, in order to determine the average GDP by country, we need to apply a function to each group we have identified. Specifically, we will need to take the average GDP over each country. Since we have already grouped by country, we next need to apply the summarise function. Like the previous verbs, the first argument in the `summarise` function is the data. The following arguments are the function to apply to each group. In the code below, we summarise the grouped data and save the summarised data into a new tibble called `gapminder_summarised`.

```{r summarise}
gapminder_summarised = summarise(gapminder_grouped, AVG_GDP = mean(GDP))

gapminder_summarised
```

We now have an answer to our question. The tibble above shows the average GDP per country since 1980. 

#### Verb 6: arrange

However, we can refine our result to provide more understanding. Currently, our data is sorted alphabetically by country. This does not provide much insight. We can use the `arrange` function to sort the data by average GDP; either ascending or descending. Like all other verbs, the first argument in the `arrange` function is the data. The following arguments are the one or more columns which you wish to sort by. In the code below, we arrange our summarised data and save our arranged data into a new tibble called `gapminder_arranged`.

```{r arranged}
gapminder_arragned = arrange(gapminder_summarised, AVG_GDP)

gapminder_arragned
```

We see, from the output above, the countries with the smallest average GDP since 1980. 

It may be more interesting, however, to sort the average GDP in descending order so we can learn which countries have the highest average GDP. To do this we simply place a - sign in front of `AVG_GDP` in the code above.

```{r arrangeddesc}
gapminder_arragned_descending = arrange(gapminder_summarised, -AVG_GDP)

gapminder_arragned_descending
```

#### Simplifying Code with the Pipe Operator: `%>%` 

After helping learners see how each function works we can introduce the pipe operator (`%>%`).  This helpful code chains together commands and passes the results of one function directly into the next function. This results in very logical data manipulation steps that are fairly easy to learn and makes the code easy to understand:

```{r pipechain}
gapminder_arragned_descending_chained =
  gapminder %>%
  select(country, year, pop, gdpPercap) %>%
  filter(year >= 1980) %>%
  mutate(GDP = gdpPercap * pop) %>%
  group_by(country) %>%
  summarise(AVG_GDP = mean(GDP)) %>%
  arrange(-AVG_GDP)

gapminder_arragned_descending_chained
```

If students struggle to understand the role of the pipe, we often explain the operator as follows: A pipe takes the result of the previous function and 'pipes' it into the first argument of the next function. In that way, we can chain together our verbs to manipulate and gain insight on the data. We find the pipe helpful in creating analysis code that is easy to read and follow. 

### Plotting and Exploratory Data Analysis (EDA)

From the preceding example, you can see one way for students to gain insight from data by manipulating the `tibble` with `dplyr` verbs. . In addition, it is important for students to gain insight from data by viewing it graphically. Let’s look briefly at some plotting basics and how to help students *quickly* create very insightful data visualizations.

#### `esquisse`

Typically, before building any models or doing other analysis, students benefit from learning basic exploratory data analysis (EDA). One tool for getting students a quick win with learning data visualization is to use `ggplot2` along with the helper package `esquisse` to give them a graphical user interface for basic `ggplot2` code  [@esquisse]. `esquisse` supports only a subset of the myriad of features available in `ggplot2` but because it is a drag and drop GUI, it is very helpful in jump starting students to see how code can take data and turn it into tangible visualizations.

Since `esquisse` is a CRAN package, install it by running `install.packages("esquisse")`. After installation, `esquisse` shows up in the *Addins* menu of RStudio shown in figure \@ref(fig:addins).

<!-- note for later: the image below has distracting code below it -- add this as an issue to fix. -->

```{r addins, fig.cap='Addins menu', echo=FALSE, eval=TRUE, out.width = "300px"}
knitr::include_graphics("03_figures/addins.png")
```

The `'ggplot2' builder` menu option opens the graphical interface for building `ggplot2` graphics using a helper UI. In figure  \@ref(fig:esquisse) we show how the `esquisse` interface appears with the `gapminder` data selected.

```{r esquisse, fig.cap='esquisse UI', echo=FALSE, eval=TRUE}
knitr::include_graphics("03_figures/esquisse.png")
```

The strength of `esquisse` is that it produces the `ggplot2` code that allows the R learner to see how to build the syntax themselves in the future. Most importantly, it reduces  the likelihood that students will get stuck when trying to make their first `ggplot2` figures. For more information about `esquisse` see the project CRAN web site: https://cran.r-project.org/web/packages/esquisse/readme/README.html

#### `ggpairs`

A supplemental technique to explore data is to look at a pairs plot. The `GGally` package provides a powerful tool with simple syntax that provide the user with clearly organized information about the data [@ggally]. As with other CRAN packages, the library should be installed  with `install.packages("GGally")`.

A pairs plot does a good job of visualizing relationships between continuous variables or character variables. In gapminder data, there are 142 different countries. For the pairs plot in figure \@ref(fig:ggpairs), we remove the `country` column then call the `ggpairs` function to generate the visualization.

```{r ggpairs, message=FALSE, warning=FALSE,fig.width=8, fig.height=7, dpi=600, fig.cap="Example Pairs Plot"}
library(GGally)
gapminder %>%
 select(-country) %>%
 ggpairs()
```

There is much to glean from the pairs plot. We see that this tool provides pairwise plot and correlations between continuous variables and histograms and boxplots between discrete and continuous variables. While the *x* axis tends to be crowded, we can still see general trends and patterns from the pairs plot.

Briefly, we can see that there is an increasing life expectancy and population as year increases as well as several countries that separate themselves from the pack. An easily creatable pairs plot like this can springboard students into further analysis an example of which we will highlight below. 

### Regression 

The first statistical modeling method that most students are taught is ordinary least squares linear regression. In the base stats package and with one additional library, R offers easy to execute and understandable tools to implement everything we would expect a student to learn in linear regression. 

To highlight these tools, let's explore the linear relationship between several variables and life expectancy (`lifeExp`) in the Gapminder data.

#### Simple Linear Regression

To implement a linear regression, we need to specify two arguments in the `lm` (linear model) function: The formula and the data. As you can see in the example below, our formula is in the format `y ~ x` - pronounced y by x. As expected, the `data` is equal to `gapminder`.

```{r mod1}
model1 = lm(formula = lifeExp ~ gdpPercap, data = gapminder)
```

R executes this command and saves it as `model1`. To retrieve our simple linear regression model, we place `model1` in the summary command below.

```{r mod1sum}
summary(model1)
```

From the output, the student sees pertinent information about the model  including the equation, a small summary of the residuals, regression coefficients, p-values, and familiar model evaluation statistics such as $R^2$ and Adjusted $R^2$. 

Adjusting the linear model is simple. Should we desire to add another factor to the model, we can do it simply by adding it to the formula like the example below.

```{r mod2}
model2 = lm(formula = lifeExp ~ gdpPercap + year, data = gapminder)

summary(model2)
```

R's linear model function is flexible enough to easily add interaction terms. To add an interaction term between `gdpPercap` and `year`, we add a colon between the independent variables. 

```{r mod3}
model3 = lm(formula = lifeExp ~ gdpPercap + year + gdpPercap:year,
            data = gapminder)

summary(model3)
```

#### Linear Regression Modeling Assumptions

One of the staples of teaching linear regression is helping students determine if their model meets the assumptions necessary for a linear model to be valid. For the purpose of illustration we'll look at the following assumptions:

1) Independent Observations
2) Normal Errors
3) Constant variance of errors (homoskedasticity)
4) Linear Relationships

Let's look briefly at how we help students think about each of these assumptions using R code where helpful.

**Independent Observations:**

To determine independence, we must know how the data was collected. There are likely independence issues as the data for each country in the Gapminder collection are likely influenced by each other. We will acknowledge this and proceed on with the other assumptions.  

Other Assumptions:

To verify the other assumptions, we need to create two plots. The residual plots and a qqplot.

To create the plots, we will rely on the `lindia` [@lindia] package that makes diagnostic plots easy. If you do not have it installed already, execute `install.packages("lindia)`. Then pass the results of a model into the `gg_diagnose` function as shown in figure \@ref(fig:lindia).

```{r lindia, fig.width=8, fig.height=8, dpi=600, message=FALSE, warning=FALSE, fig.cap="Example Diagnostic Plot"}
library(lindia)
model2 %>%
 gg_diagnose(plot.all = TRUE, boxcox = TRUE)
```

The `gg_diagnose` command provides students a one stop shop for all diagnostic plots to evaluate the OLS assumptions. 

**Normal Errors:**

From the plots, we see that our normality is slightly skewed in the positive direction and `gdpPercap` appears to be the culprit. The `qqplot` also supports this conclusion as the observed standardized residuals are more extreme than what we would expect if the residuals followed the ideal theoretical *z* distribution. 

**Constant Variance:**

Variance of the residuals appears to remain constant at all levels of each *x* variable. 

**Linear Relationships:**

The linearity assumption, however, seems to be violated at the `gdpPercap` variable and we also see evidence of this in the residuals vs fitted plot.  In both plots, instead of seeing a patternless array of errors, we see an arching trend indicating a non-linear relationship between at least one of the x variables and `lifeExp`.  The residuals start negative, peak in the positive and then taper off negative again as each value on the x axis increases.  

#### Transformations and Residual Revaluation

From our previous critique, and after some instruction on how to interpret the results, students should have all the information available to them to make decisions about how to improve their model. To improve our example analysis, we will apply a transformation on `gdpPercap` to improve linearity and normality of errors. A transformation on the *y* variable is not necessary as we have no issues with constant variance and the Box Cox plot shows no value of lambda that maximizes the log-likelihood of our model. 

```{r modadj}
modeladj = lm(formula = lifeExp ~ log(gdpPercap) + year, data = gapminder)

summary(modeladj)
```

Since our coefficients are still significant, we will take a look at the diagnostic plots to see if our assumptions are more plausible. R makes it easy to repeat the same plots on the new model. Figure \@ref(fig:lindiadiag2) shows the diagnostics after we perform the transform. 

```{r lindiadiag2, fig.width=8, fig.height=8, dpi=600, warning=FALSE,message=FALSE, fig.cap="Improved Model Diagnostic Plot"}
modeladj %>%
 gg_diagnose(plot.all = TRUE, boxcox = TRUE) 
```

While there is more work to be done to validate this model, we can see that our transformation has improved the normality of errors and has improved the linearity of `gdppercap`. 

## Conclusion

R, along with supporting CRAN packages can be an excellent platform on which to teach analysis and modeling to students. The RStudio.cloud online environment is a solid hosted platform that helps reduce the friction of getting students started with R and add on packages from CRAN like `tidyverse`, `lindia`, `GGally`, and `esquisse` can be combined together in a teaching environment to help students get tangible results quickly. We have found that students are willing to learn a considerable amount of R if we can make the on-ramp to the basics quick and easy. We hope these tools help you and your students get up and running quickly with using R for data analysis and modeling. We wholeheartedly believe Adam Smith will be pleased to see the ease of the masters and the ease of the students aligned.

# Bibliography
